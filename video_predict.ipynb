{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitactionregvirtualenv7e73233028ea4f129999eb632b13f22b",
   "display_name": "Python 3.7.4 64-bit ('action_reg': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# from data_helper import readfile_to_dict\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from model_ML import create_model_pretrain, create_model_Conv3D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "dim = (120,120)\n",
    "n_sequence = 10\n",
    "n_channels = 3\n",
    "n_output = 5\n",
    "batch_size = 1\n",
    "\n",
    "X = np.empty((batch_size, n_sequence, *dim, n_channels)) # X : (n_samples, *dim, n_channels)\n",
    "Y = np.empty((batch_size), dtype=int)\n",
    "\n",
    "\n",
    "## Predict\n",
    "# weights_path = 'BUPT-RGB-Crop-96-0.92-0.88.hdf5'\n",
    "weights_path = 'BUPT-RGBdiff-crop-Conv3D-verytiny-dataset02-1600-0.88-0.77.hdf5'\n",
    "#'BUPT-2d-equalsplit-RGBdif-72-0.98-0.90.hdf5'\n",
    "# weights_path = 'KARD-aug-RGBdif-40-0.92-0.98.hdf5'\n",
    "# model = create_model_pretrain(dim, n_sequence, n_channels, n_output, 'MobileNetV2')\n",
    "model = create_model_Conv3D(dim, n_sequence, n_channels, n_output) \n",
    "model.load_weights(weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRGBdiff(sequence_img):\n",
    "    'keep first frame as rgb data, other is use RGBdiff for temporal data'\n",
    "    length = len(sequence_img)\n",
    "    sh = sequence_img.shape\n",
    "    new_sequence = np.zeros((sh[0],sh[1],sh[2],sh[3])) # (frame, w,h,3)\n",
    "\n",
    "    # find RGBdiff frame 1 to last frame\n",
    "    for i in range(length-1,0,-1): # count down\n",
    "        new_sequence[i] = cv2.subtract(sequence_img[i],sequence_img[i-1])\n",
    "    \n",
    "    new_sequence[0] = sequence_img[0] # first frame as rgb data\n",
    "\n",
    "    return new_sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sampling_frame( len_frames):   \n",
    "    '''\n",
    "    Sampling n_sequence frame from video file\n",
    "    Output: n_sequence index from sampling algorithm \n",
    "    '''     \n",
    "    \n",
    "    random_sample_range = 1\n",
    "    # Randomly choose sample interval and start frame\n",
    "    sample_interval = 4#np.random.randint(1, random_sample_range + 1)\n",
    "    # print('sample_interval:',sample_interval)\n",
    "    print(len_frames - sample_interval * n_sequence + 1, len_frames )\n",
    "    start_i = np.random.randint(0, len_frames - sample_interval * n_sequence + 1)\n",
    "   \n",
    "\n",
    "    # sample_interval = len_frames//n_sequence\n",
    "    # start_i = 0\n",
    "    \n",
    "    # Extract frames as tensors\n",
    "    index_sampling = []\n",
    "    end_i = sample_interval * n_sequence + start_i\n",
    "    for i in range(start_i, end_i, sample_interval):\n",
    "        if len(index_sampling) < n_sequence:\n",
    "            index_sampling.append(i)\n",
    "    \n",
    "    return index_sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one():\n",
    "    \n",
    "\n",
    "    # path_file = 'F:\\\\Master Project\\\\Dataset\\\\BasketBall-RGB\\\\'+action+'\\\\'+action+'00.mp4'\n",
    "    \n",
    "    cap = cv2.VideoCapture(path_file)\n",
    "    length_file = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # get length of frames,\n",
    "    print(length_file)\n",
    "    index_sampling = get_sampling_frame(length_file) # get index to sampling         \n",
    "    for j, n_pic in enumerate(index_sampling):\n",
    "        print(j, n_pic)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n_pic)\n",
    "        ret, frame = cap.read()\n",
    "        # edge = cv2.Canny(frame,50,50)\n",
    "        # frame = cv2.Laplacian(frame,cv2.CV_64F) \n",
    "        # frame = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=3)\n",
    "        # # temp = edge/255.0\n",
    "        # for c in range(3):\n",
    "        #     frame[:,:,c] = edge\n",
    "\n",
    "        new_image = cv2.resize(frame, dim)   \n",
    "        new_image = new_image  \n",
    "        # edge = cv2.Canny(new_image,100,200) \n",
    "        # temp = edge/255.0\n",
    "        # for c in range(3):\n",
    "        #     new_image[:,:,c] = temp\n",
    "\n",
    "        X[0,j,:,:,:] = new_image\n",
    "        \n",
    "        # cv2.imshow('Frame',frame)\n",
    "\n",
    "\n",
    "        # cv2.waitKey(500)\n",
    "\n",
    "    cap.release()\n",
    "    print(X.shape)\n",
    "\n",
    "    X[0,] = sequence_augment(X[0,])/255.0  \n",
    "    X[0,] = calculateRGBdiff(X[0,])\n",
    "\n",
    "    for i in range(n_sequence):    \n",
    "        cv2.imshow('Frame',X[0,i])\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    result = model.predict(X)\n",
    "    print(np.around(result,3))\n",
    "    print(np.max(result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_gen = ImageDataGenerator(fill_mode='nearest')\n",
    "def sequence_augment(sequence):\n",
    "        name_list = ['rotate','width_shift','height_shift',\n",
    "                    'brightness','flip_horizontal','width_zoom',\n",
    "                    'height_zoom']\n",
    "        # dictkey_list = ['theta','ty','tx',\n",
    "        #             'brightness','flip_horizontal','zy',\n",
    "        #             'zx']\n",
    "        dictkey_list = ['zy','zx']#['ty','tx','theta','zy','zx']\n",
    "        random_aug = 1 #np.random.randint(2, 5) # random 0-4 augmentation method\n",
    "        pick_idx = np.random.choice(len(dictkey_list), random_aug, replace=False) #\n",
    "        dict_input = {}\n",
    "        for i in pick_idx:\n",
    "            if dictkey_list[i] == 'theta':\n",
    "                dict_input['theta'] = 5 #np.random.randint(-10, 10)\n",
    "\n",
    "            elif dictkey_list[i] == 'ty': # width_shift\n",
    "                dict_input['ty'] = 20#np.random.randint(-60, 60)\n",
    "\n",
    "            elif dictkey_list[i] == 'tx': # height_shift\n",
    "                dict_input['tx'] = 10#np.random.randint(-30, 30)\n",
    "\n",
    "            elif dictkey_list[i] == 'brightness': \n",
    "                dict_input['brightness'] = np.random.uniform(0.15,1)\n",
    "\n",
    "            elif dictkey_list[i] == 'flip_horizontal': \n",
    "                dict_input['flip_horizontal'] = True\n",
    "\n",
    "            elif dictkey_list[i] == 'zy': # width_zoom\n",
    "                dict_input['zy'] = 1.3#np.random.uniform(0.5,1.5)\n",
    "\n",
    "            elif dictkey_list[i] == 'zx': # height_zoom\n",
    "                dict_input['zx'] = 1.3#np.random.uniform(0.5,1.5)\n",
    "        \n",
    "        sh = sequence.shape\n",
    "        new_sequence = np.zeros((sh[0],sh[1],sh[2],sh[3]))\n",
    "\n",
    "        print(dict_input)\n",
    "        for i in range(sh[0]):\n",
    "            new_sequence[i] = aug_gen.apply_transform(sequence[i],dict_input)\n",
    "        \n",
    "        return new_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "218\n179 218\n0 116\n1 120\n2 124\n3 128\n4 132\n5 136\n6 140\n7 144\n8 148\n9 152\n(1, 10, 120, 120, 3)\n{'zx': 1.3}\n[[0.7 0.  0.  0.3 0. ]]\n0.69972956\n"
    }
   ],
   "source": [
    "sub_folder = 'peach'\n",
    "action = 'walk'\n",
    "base_path = 'F:\\\\Master Project\\\\'\n",
    "\n",
    "# base_path = 'D:\\\\Peach\\\\'\n",
    "# path_file = base_path+'Dataset\\\\sit_stand\\\\'+action+'\\\\'+action+'03_04.mp4'\n",
    "# path_file = base_path+'Dataset\\\\KARD-split\\\\'+action+'\\\\'+action+'_s09_e03.mp4'\n",
    "# path_file = base_path+'Dataset\\\\BUPT-dataset\\\\RGBdataset_crop\\\\'+sub_folder+'\\\\'+action+'\\\\'+action+'04_02_00.mp4'\n",
    "path_file = base_path+'Dataset\\\\sit_stand_crop02\\\\'+sub_folder+'\\\\'+action+'\\\\'+action+'04_01_03.mp4'\n",
    "\n",
    "run_one()\n",
    "\n",
    "# run, sit, stand, walk, standup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}