{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\nF:\\Master Project\\environment\\action_reg\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  warnings.warn('`input_shape` is undefined or non-square, '\n"
    }
   ],
   "source": [
    "# from data_helper import readfile_to_dict\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from model_ML import create_model_pretrain\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "dim = (224,224)\n",
    "n_sequence = 8\n",
    "n_channels = 3\n",
    "n_output = 5\n",
    "batch_size = 1\n",
    "\n",
    "X = np.empty((batch_size, n_sequence, *dim, n_channels)) # X : (n_samples, *dim, n_channels)\n",
    "Y = np.empty((batch_size), dtype=int)\n",
    "\n",
    "\n",
    "## Predict\n",
    "weights_path = 'BUPT-2d-addall-RGBdiff-half-34-0.90-0.85.hdf5'\n",
    "# weights_path = 'KARD-aug-RGBdif-40-0.92-0.98.hdf5'\n",
    "model = create_model_pretrain(dim, n_sequence, n_channels, n_output, 'MobileNetV2')\n",
    "model.load_weights(weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRGBdiff(sequence_img):\n",
    "    'keep first frame as rgb data, other is use RGBdiff for temporal data'\n",
    "    length = len(sequence_img)\n",
    "    sh = sequence_img.shape\n",
    "    new_sequence = np.zeros((sh[0],sh[1],sh[2],sh[3])) # (frame, w,h,3)\n",
    "\n",
    "    # find RGBdiff frame 1 to last frame\n",
    "    for i in range(length-1,3,-1): # count down\n",
    "        new_sequence[i] = cv2.subtract(sequence_img[i],sequence_img[i-1])\n",
    "    \n",
    "    new_sequence[:4] = sequence_img[:4] # first frame as rgb data\n",
    "\n",
    "    return new_sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sampling_frame( len_frames):   \n",
    "    '''\n",
    "    Sampling n_sequence frame from video file\n",
    "    Output: n_sequence index from sampling algorithm \n",
    "    '''     \n",
    "    \n",
    "    random_sample_range = 1\n",
    "    # Randomly choose sample interval and start frame\n",
    "    sample_interval = 4#np.random.randint(1, random_sample_range + 1)\n",
    "    # print('sample_interval:',sample_interval)\n",
    "    print(len_frames - sample_interval * n_sequence + 1, len_frames )\n",
    "    start_i = np.random.randint(0, len_frames - sample_interval * n_sequence + 1)\n",
    "   \n",
    "\n",
    "    # sample_interval = len_frames//n_sequence\n",
    "    # start_i = 0\n",
    "    \n",
    "    # Extract frames as tensors\n",
    "    index_sampling = []\n",
    "    end_i = sample_interval * n_sequence + start_i\n",
    "    for i in range(start_i, end_i, sample_interval):\n",
    "        if len(index_sampling) < n_sequence:\n",
    "            index_sampling.append(i)\n",
    "    \n",
    "    return index_sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one():\n",
    "    \n",
    "\n",
    "    # path_file = 'F:\\\\Master Project\\\\Dataset\\\\BasketBall-RGB\\\\'+action+'\\\\'+action+'00.mp4'\n",
    "    \n",
    "    cap = cv2.VideoCapture(path_file)\n",
    "    length_file = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # get length of frames,\n",
    "    print(length_file)\n",
    "    index_sampling = get_sampling_frame(length_file) # get index to sampling         \n",
    "    for j, n_pic in enumerate(index_sampling):\n",
    "        print(j, n_pic)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n_pic)\n",
    "        ret, frame = cap.read()\n",
    "        # edge = cv2.Canny(frame,50,50)\n",
    "        # frame = cv2.Laplacian(frame,cv2.CV_64F) \n",
    "        # frame = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=3)\n",
    "        # # temp = edge/255.0\n",
    "        # for c in range(3):\n",
    "        #     frame[:,:,c] = edge\n",
    "\n",
    "        new_image = cv2.resize(frame, dim)   \n",
    "        new_image = new_image/255.0    \n",
    "        # edge = cv2.Canny(new_image,100,200) \n",
    "        # temp = edge/255.0\n",
    "        # for c in range(3):\n",
    "        #     new_image[:,:,c] = temp\n",
    "\n",
    "        X[0,j,:,:,:] = new_image\n",
    "        \n",
    "        # cv2.imshow('Frame',frame)\n",
    "\n",
    "\n",
    "        # cv2.waitKey(500)\n",
    "\n",
    "    cap.release()\n",
    "    print(X.shape)\n",
    "\n",
    "\n",
    "    X[0,] = calculateRGBdiff(X[0,])\n",
    "\n",
    "    for i in range(n_sequence):    \n",
    "        cv2.imshow('Frame',X[0,i])\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    result = model.predict(X)\n",
    "    print(np.around(result,3))\n",
    "    print(np.max(result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "134\n103 134\n0 82\n1 86\n2 90\n3 94\n4 98\n5 102\n6 106\n7 110\n(1, 8, 224, 224, 3)\n[[-3.379  6.614 -0.739 -4.758 -2.311]]\n6.6139164\n"
    }
   ],
   "source": [
    "sub_folder = 'peach'\n",
    "action = 'sit'\n",
    "base_path = 'F:\\\\Master Project\\\\'\n",
    "\n",
    "# base_path = 'D:\\\\Peach\\\\'\n",
    "# path_file = base_path+'Dataset\\\\sit_stand\\\\'+action+'\\\\'+action+'03_04.mp4'\n",
    "# path_file = base_path+'Dataset\\\\KARD-split\\\\'+action+'\\\\'+action+'_s09_e03.mp4'\n",
    "path_file = base_path+'Dataset\\\\BUPT-dataset\\\\RGBdataset\\\\'+sub_folder+'\\\\'+action+'\\\\'+action+'01_00.mp4'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "run_one()\n",
    "\n"
   ]
  }
 ]
}